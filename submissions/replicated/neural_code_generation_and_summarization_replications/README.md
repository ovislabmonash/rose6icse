# Appendix to PDF Submission:

## Results:

* Raw, and difficulty-adjusted (BOS-adjusted) BLEU4 results, for each model-dataset combination: https://www.dropbox.com/sh/bix3vlvtbu4n58g/AACNJZIEHvy9JtjAqP79vThEa?dl=0

## Link to original studies being replicated (generative models, Bi-LSTM and Transformer):

1. [LeClair 2019] **A Neural Model for Generating Natural Language Summaries of Program Subroutines**
  * Paper link with authors list and emails: https://arxiv.org/pdf/1902.01954.pdf
  * Replication package: https://s3.us-east-2.amazonaws.com/icse2018/index.html 
2. [Yin 2018] [Conala Challenge's Bi-LSTM with attention seq2seq baseline model] **Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow**
  * Paper link with authors list and emails: https://arxiv.org/pdf/1805.08949.pdf 
  * Replication package: https://github.com/conala-corpus/conala-baseline/ 
  * Challenge dataset page (The Code/Natural Language Challenge): https://conala-corpus.github.io/

## Link to original study being reproduced (semantic search model, baseline):

1. [Sachdev 2018] **Retrieval on Source Code: A Neural Code Search** 
  * Paper link with authors list and emails: https://people.eecs.berkeley.edu/~ksen/papers/ncs.pdf 
  * Repository for my reproduction, to be cleaned before publication: https://github.com/nico3865/ExtractionOfAPIUsagePatterns5
